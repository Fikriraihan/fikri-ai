# ğŸ¤– Fikri AI â€” Personalized Assistant Backend

This is the backend for **Fikri Raihan's personal AI assistant**, built using FastAPI, LangChain, and OpenAI to answer questions about Fikri Raihanâ€™s career, projects, tech stack, and experience â€” just like a portfolio chatbot..

ğŸ‘‰ Try the frontend here: [fikri-portofolio.netlify.app](https://fikri-portofolio.netlify.app)  
âš ï¸ Backend hosted on Railway (may take time to spin up on free tier)

---

## âœ¨ Features

- ğŸ” **Retrieval-Augmented Generation (RAG)** using LangChain & Chroma
- ğŸ§  **Memory-aware chat** with conversation context
- ğŸ—‚ï¸ Smart document indexing from Markdown, PDF, and TXT
- ğŸŒ API-ready backend for frontend integration (e.g. Netlify)
- ğŸš€ Production-ready via Docker

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                  # FastAPI app (main entry point)
â”œâ”€â”€ Dockerfile              # For production deployment
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ pyproject.toml          # Project metadata
â”œâ”€â”€ .gitignore
â”œâ”€â”€ fikri/                  # Knowledge base folder (markdown, PDFs, etc)
â”‚   â”œâ”€â”€ interview/
â”‚   â”œâ”€â”€ Planet Surf/
â”‚   â”œâ”€â”€ Reycom Document Solusi/
â”‚   â””â”€â”€ me/
```

---

## ğŸ—ï¸ Tech Stack

| Area               | Stack/Library                           |
| ------------------ | --------------------------------------- |
| **API Server**     | FastAPI, Uvicorn                        |
| **RAG Pipeline**   | LangChain, OpenAI (GPT-4o-mini), Chroma |
| **Embeddings**     | `text-embedding-3-small` (OpenAI)       |
| **Frontend**       | React, Vite, Zustand (in separate repo) |
| **Deployment**     | Railway (API), Netlify (frontend)       |
| **Document Types** | Markdown (`.md`), PDF, TXT              |

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/fikriraihan/fikri-ai.git
cd fikri-ai
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

Or, if using `uv`:

```bash
uv pip install -r requirements.txt
```

### 3. Set Up Environment Variables

Create a `.env` file with your OpenAI API key and other configs:

```
OPENAI_API_KEY=your-openai-key
REBUILD_VECTOR=false
```

### 4. Run the App

```bash
uvicorn app:app --reload
```

### 5. (Optional) Run with Docker

```bash
docker build -t fikri-ai .
docker run -p 8000:8000 fikri-ai
```

---

## ğŸ“ Adding Knowledge

- Place new Markdown, PDF, or TXT files in the `fikri/` directory.
- The vector store will auto-rebuild if `REBUILD_VECTOR=true` is set.

---

## ğŸ› ï¸ Development

- Main logic in `app.py`
- Uses LangChain for RAG and ChromaDB for vector storage
- Custom prompt templates ensure answers are always up-to-date and grouped by company/project

---

## ğŸ“„ Example API Usage

```python
import requests

response = requests.post(
    "http://localhost:8000/chat",
    json={"question": "What projects did Fikri work on at Planet Surf?"}
)
print(response.json())
```

---
